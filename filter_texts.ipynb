{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzmdLvdTmt68Et6RCiqri4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mollyapsel/RegionalLinguisticBias/blob/main/filter_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCYsTKgw4DsU",
        "outputId": "fb96a644-2087-4bac-f817-618af0a2a520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Michelle Molly/Corpus Data/USA Text/Clean_text.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYjqhT2e5Gwh",
        "outputId": "63efa140-4410-4f83-c485-4177aebcc26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Michelle Molly/Corpus Data/USA Text/Clean_text.zip\n",
            "   creating: Clean_text/\n",
            "  inflating: Clean_text/14-01-us.json  \n",
            "  inflating: Clean_text/14-11-us.json  \n",
            "  inflating: Clean_text/20-03-us4.json  \n",
            "  inflating: Clean_text/21-07-us3.json  \n",
            "  inflating: Clean_text/20_06-us5.json  \n",
            "  inflating: Clean_text/11-10-us.json  \n",
            "  inflating: Clean_text/20_07-us5.json  \n",
            "  inflating: Clean_text/23-08-us3.json  \n",
            "  inflating: Clean_text/22-04-us1.json  \n",
            "  inflating: Clean_text/22-05-us1.json  \n",
            "  inflating: Clean_text/15-07-us.json  \n",
            "  inflating: Clean_text/21-01-us4.json  \n",
            "  inflating: Clean_text/23-06-us1.json  \n",
            "  inflating: Clean_text/23-07-us1.json  \n",
            "  inflating: Clean_text/20-04-us3.json  \n",
            "  inflating: Clean_text/20-05-us3.json  \n",
            "  inflating: Clean_text/22-10-us5.json  \n",
            "  inflating: Clean_text/19-07-us4.json  \n",
            "  inflating: Clean_text/10-06-us.json  \n",
            "  inflating: Clean_text/22-11-us5.json  \n",
            "  inflating: Clean_text/21-09-us1.json  \n",
            "  inflating: Clean_text/21-08-us1.json  \n",
            "  inflating: Clean_text/12-05-us.json  \n",
            "  inflating: Clean_text/23-03-us3.json  \n",
            "  inflating: Clean_text/11-09-us.json  \n",
            "  inflating: Clean_text/20-01-us1.json  \n",
            "  inflating: Clean_text/20-03-us8.json  \n",
            "  inflating: Clean_text/text_17-03-US.json  \n",
            "  inflating: Clean_text/20-09-us4.json  \n",
            "  inflating: Clean_text/21-05-us6.json  \n",
            "  inflating: Clean_text/21-04-us6.json  \n",
            "  inflating: Clean_text/14-08-us.json  \n",
            "  inflating: Clean_text/22-07-us4.json  \n",
            "  inflating: Clean_text/19-11-us5.json  \n",
            "  inflating: Clean_text/19-10-us5.json  \n",
            "  inflating: Clean_text/22-06-us4.json  \n",
            "  inflating: Clean_text/20-12-us2.json  \n",
            "  inflating: Clean_text/21-01-us8.json  \n",
            "  inflating: Clean_text/21-03-us1.json  \n",
            "  inflating: Clean_text/21-02-us1.json  \n",
            "  inflating: Clean_text/13-03-us.json  \n",
            "  inflating: Clean_text/22-01-us3.json  \n",
            "  inflating: Clean_text/23-05-us4.json  \n",
            "  inflating: Clean_text/23-04-us4.json  \n",
            "  inflating: Clean_text/21-11-us2.json  \n",
            "  inflating: Clean_text/21-10-us2.json  \n",
            "  inflating: Clean_text/16-02-us.json  \n",
            "  inflating: Clean_text/18-07-us.json  \n",
            "  inflating: Clean_text/19-05-us1.json  \n",
            "  inflating: Clean_text/19-04-us1.json  \n",
            "  inflating: Clean_text/18-09-us2.json  \n",
            "  inflating: Clean_text/text_17-12-US.json  \n",
            "  inflating: Clean_text/text_17-02-US.json  \n",
            "  inflating: Clean_text/22-12-us1.json  \n",
            "  inflating: Clean_text/12-04-us.json  \n",
            "  inflating: Clean_text/21-11-us3.json  \n",
            "  inflating: Clean_text/21-10-us3.json  \n",
            "  inflating: Clean_text/23-05-us5.json  \n",
            "  inflating: Clean_text/23-04-us5.json  \n",
            "  inflating: Clean_text/11-08-us.json  \n",
            "  inflating: Clean_text/14-09-us.json  \n",
            "  inflating: Clean_text/22-01-us2.json  \n",
            "  inflating: Clean_text/21-06-02-US1.json  \n",
            "  inflating: Clean_text/21-01-us9.json  \n",
            "  inflating: Clean_text/21-03-us0.json  \n",
            "  inflating: Clean_text/21-02-us0.json  \n",
            "  inflating: Clean_text/13-12-us.json  \n",
            "  inflating: Clean_text/13-02-us.json  \n",
            "  inflating: Clean_text/20-12-us3.json  \n",
            "  inflating: Clean_text/text_18-01-US.json  \n",
            "  inflating: Clean_text/22-07-us5.json  \n",
            "  inflating: Clean_text/19-11-us4.json  \n",
            "  inflating: Clean_text/19-10-us4.json  \n",
            "  inflating: Clean_text/22-06-us5.json  \n",
            "  inflating: Clean_text/21-05-us7.json  \n",
            "  inflating: Clean_text/21-04-us7.json  \n",
            "  inflating: Clean_text/20_07-us8.json  \n",
            "  inflating: Clean_text/20_06-us8.json  \n",
            "  inflating: Clean_text/20-09-us5.json  \n",
            "  inflating: Clean_text/18-06-us.json  \n",
            "  inflating: Clean_text/23-03-us2.json  \n",
            "  inflating: Clean_text/16-03-us.json  \n",
            "  inflating: Clean_text/22-10-us4.json  \n",
            "  inflating: Clean_text/19-07-us5.json  \n",
            "  inflating: Clean_text/22-11-us4.json  \n",
            "  inflating: Clean_text/14-10-us.json  \n",
            "  inflating: Clean_text/20-04-us2.json  \n",
            "  inflating: Clean_text/20-05-us2.json  \n",
            "  inflating: Clean_text/18-11-us1.json  \n",
            "  inflating: Clean_text/21-01-us5.json  \n",
            "  inflating: Clean_text/11-01-us.json  \n",
            "  inflating: Clean_text/11-11-us.json  \n",
            "  inflating: Clean_text/19-12-us1.json  \n",
            "  inflating: Clean_text/19-11-us8.json  \n",
            "  inflating: Clean_text/23-08-us2.json  \n",
            "  inflating: Clean_text/20_06-us4.json  \n",
            "  inflating: Clean_text/20_07-us4.json  \n",
            "  inflating: Clean_text/15-06-us.json  \n",
            "  inflating: Clean_text/21-07-us2.json  \n",
            "  inflating: Clean_text/20-03-us5.json  \n",
            "  inflating: Clean_text/19-01-us2.json  \n",
            "  inflating: Clean_text/10-07-us.json  \n",
            "  inflating: Clean_text/23-03-us5.json  \n",
            "  inflating: Clean_text/20-01-us7.json  \n",
            "  inflating: Clean_text/20-09-us2.json  \n",
            "  inflating: Clean_text/text_17-10-US.json  \n",
            "  inflating: Clean_text/21-04-us0.json  \n",
            "  inflating: Clean_text/21-05-us0.json  \n",
            "  inflating: Clean_text/22-06-us2.json  \n",
            "  inflating: Clean_text/19-10-us3.json  \n",
            "  inflating: Clean_text/19-11-us3.json  \n",
            "  inflating: Clean_text/22-07-us2.json  \n",
            "  inflating: Clean_text/20-12-us4.json  \n",
            "  inflating: Clean_text/12-06-us.json  \n",
            "  inflating: Clean_text/21-02-us7.json  \n",
            "  inflating: Clean_text/21-03-us7.json  \n",
            "  inflating: Clean_text/18-04-us.json  \n",
            "  inflating: Clean_text/16-01-us.json  \n",
            "  inflating: Clean_text/22-01-us5.json  \n",
            "  inflating: Clean_text/23-04-us2.json  \n",
            "  inflating: Clean_text/23-05-us2.json  \n",
            "  inflating: Clean_text/text_18-03-US.json  \n",
            "  inflating: Clean_text/21-10-us4.json  \n",
            "  inflating: Clean_text/13-10-us.json  \n",
            "  inflating: Clean_text/21-11-us4.json  \n",
            "  inflating: Clean_text/text_17-09-US.json  \n",
            "  inflating: Clean_text/11-03-us.json  \n",
            "  inflating: Clean_text/20-03-us2.json  \n",
            "  inflating: Clean_text/21-07-us5.json  \n",
            "  inflating: Clean_text/14-02-us.json  \n",
            "  inflating: Clean_text/20_07-us3.json  \n",
            "  inflating: Clean_text/20_06-us3.json  \n",
            "  inflating: Clean_text/14-12-us.json  \n",
            "  inflating: Clean_text/23-08-us5.json  \n",
            "  inflating: Clean_text/20-12-us8.json  \n",
            "  inflating: Clean_text/20-11-us1.json  \n",
            "  inflating: Clean_text/20-10-us1.json  \n",
            "  inflating: Clean_text/19-12-us6.json  \n",
            "  inflating: Clean_text/10-05-us.json  \n",
            "  inflating: Clean_text/21-01-us2.json  \n",
            "  inflating: Clean_text/13-09-us.json  \n",
            "  inflating: Clean_text/21-12-us1.json  \n",
            "  inflating: Clean_text/16-08-us.json  \n",
            "  inflating: Clean_text/20-05-us5.json  \n",
            "  inflating: Clean_text/20-04-us5.json  \n",
            "  inflating: Clean_text/15-04-us.json  \n",
            "  inflating: Clean_text/22-11-us3.json  \n",
            "  inflating: Clean_text/19-07-us2.json  \n",
            "  inflating: Clean_text/19-06-us2.json  \n",
            "  inflating: Clean_text/22-10-us3.json  \n",
            "  inflating: Clean_text/22-11-us2.json  \n",
            "  inflating: Clean_text/19-07-us3.json  \n",
            "  inflating: Clean_text/22-10-us2.json  \n",
            "  inflating: Clean_text/11-02-us.json  \n",
            "  inflating: Clean_text/18-10-us-2.json  \n",
            "  inflating: Clean_text/11-12-us.json  \n",
            "  inflating: Clean_text/20-05-us4.json  \n",
            "  inflating: Clean_text/20-04-us4.json  \n",
            "  inflating: Clean_text/text_17-08-US.json  \n",
            "  inflating: Clean_text/22-03-us1.json  \n",
            "  inflating: Clean_text/22-02-us1.json  \n",
            "  inflating: Clean_text/21-01-us3.json  \n",
            "  inflating: Clean_text/14-03-us.json  \n",
            "  inflating: Clean_text/19-12-us7.json  \n",
            "  inflating: Clean_text/23-08-us4.json  \n",
            "  inflating: Clean_text/20-12-us9.json  \n",
            "  inflating: Clean_text/20_07-us2.json  \n",
            "  inflating: Clean_text/20_06-us2.json  \n",
            "  inflating: Clean_text/10-04-us.json  \n",
            "  inflating: Clean_text/21-07-us4.json  \n",
            "  inflating: Clean_text/13-08-us.json  \n",
            "  inflating: Clean_text/19-08-us1.json  \n",
            "  inflating: Clean_text/19-09-us1.json  \n",
            "  inflating: Clean_text/16-09-us.json  \n",
            "  inflating: Clean_text/20-03-us3.json  \n",
            "  inflating: Clean_text/15-05-us.json  \n",
            "  inflating: Clean_text/23-01-us1.json  \n",
            "  inflating: Clean_text/22-09-us1.json  \n",
            "  inflating: Clean_text/22-08-us1.json  \n",
            "  inflating: Clean_text/21-10-us5.json  \n",
            "  inflating: Clean_text/21-11-us5.json  \n",
            "  inflating: Clean_text/23-04-us3.json  \n",
            "  inflating: Clean_text/18-12-us2.json  \n",
            "  inflating: Clean_text/23-05-us3.json  \n",
            "  inflating: Clean_text/22-01-us4.json  \n",
            "  inflating: Clean_text/12-07-us.json  \n",
            "  inflating: Clean_text/text_17-11-US.json  \n",
            "  inflating: Clean_text/text_17-01-US.json  \n",
            "  inflating: Clean_text/21-02-us6.json  \n",
            "  inflating: Clean_text/21-03-us6.json  \n",
            "  inflating: Clean_text/20-12-us5.json  \n",
            "  inflating: Clean_text/16-10-us.json  \n",
            "  inflating: Clean_text/22-06-us3.json  \n",
            "  inflating: Clean_text/19-10-us2.json  \n",
            "  inflating: Clean_text/19-11-us2.json  \n",
            "  inflating: Clean_text/22-07-us3.json  \n",
            "  inflating: Clean_text/21-04-us1.json  \n",
            "  inflating: Clean_text/21-05-us1.json  \n",
            "  inflating: Clean_text/20-09-us3.json  \n",
            "  inflating: Clean_text/18-05-us.json  \n",
            "  inflating: Clean_text/20-01-us6.json  \n",
            "  inflating: Clean_text/23-03-us4.json  \n",
            "  inflating: Clean_text/13-11-us.json  \n",
            "  inflating: Clean_text/13-01-us.json  \n",
            "  inflating: Clean_text/22-12-us4.json  \n",
            "  inflating: Clean_text/22-08-us2.json  \n",
            "  inflating: Clean_text/22-09-us2.json  \n",
            "  inflating: Clean_text/18-12-us1.json  \n",
            "  inflating: Clean_text/text_16-12-US.json  \n",
            "  inflating: Clean_text/13-04-us.json  \n",
            "  inflating: Clean_text/21-06-02-US4.json  \n",
            "  inflating: Clean_text/21-03-us5.json  \n",
            "  inflating: Clean_text/21-02-us5.json  \n",
            "  inflating: Clean_text/10-08-us.json  \n",
            "  inflating: Clean_text/20-12-us6.json  \n",
            "  inflating: Clean_text/19-11-us1.json  \n",
            "  inflating: Clean_text/19-10-us1.json  \n",
            "  inflating: Clean_text/19-12-us8.json  \n",
            "  inflating: Clean_text/21-05-us2.json  \n",
            "  inflating: Clean_text/21-04-us2.json  \n",
            "  inflating: Clean_text/12-02-us.json  \n",
            "  inflating: Clean_text/12-12-us.json  \n",
            "  inflating: Clean_text/20-01-us5.json  \n",
            "  inflating: Clean_text/text_17-04-US.json  \n",
            "  inflating: Clean_text/21-09-us5.json  \n",
            "  inflating: Clean_text/21-08-us5.json  \n",
            "  inflating: Clean_text/18-10-us-1.json  \n",
            "  inflating: Clean_text/22-10-us1.json  \n",
            "  inflating: Clean_text/22-11-us1.json  \n",
            "  inflating: Clean_text/23-06-us5.json  \n",
            "  inflating: Clean_text/23-07-us5.json  \n",
            "  inflating: Clean_text/21-12-us3.json  \n",
            "  inflating: Clean_text/10-11-us.json  \n",
            "  inflating: Clean_text/10-01-us.json  \n",
            "  inflating: Clean_text/15-10-us.json  \n",
            "  inflating: Clean_text/22-02-us2.json  \n",
            "  inflating: Clean_text/22-03-us2.json  \n",
            "  inflating: Clean_text/21-02-us9.json  \n",
            "  inflating: Clean_text/21-03-us9.json  \n",
            "  inflating: Clean_text/21-01-us0.json  \n",
            "  inflating: Clean_text/22-04-us5.json  \n",
            "  inflating: Clean_text/19-12-us4.json  \n",
            "  inflating: Clean_text/22-05-us5.json  \n",
            "  inflating: Clean_text/20-10-us3.json  \n",
            "  inflating: Clean_text/20-11-us3.json  \n",
            "  inflating: Clean_text/11-07-us.json  \n",
            "  inflating: Clean_text/20_06-us1.json  \n",
            "  inflating: Clean_text/20_07-us1.json  \n",
            "  inflating: Clean_text/19-09-us2.json  \n",
            "  inflating: Clean_text/19-08-us2.json  \n",
            "  inflating: Clean_text/14-06-us.json  \n",
            "  inflating: Clean_text/23-01-us2.json  \n",
            "  inflating: Clean_text/23-01-us3.json  \n",
            "  inflating: Clean_text/10-10-us.json  \n",
            "  inflating: Clean_text/20-03-us1.json  \n",
            "  inflating: Clean_text/20-01-us8.json  \n",
            "  inflating: Clean_text/18-08-us.json  \n",
            "  inflating: Clean_text/19-09-us3.json  \n",
            "  inflating: Clean_text/19-08-us3.json  \n",
            "  inflating: Clean_text/20-10-us2.json  \n",
            "  inflating: Clean_text/15-11-us.json  \n",
            "  inflating: Clean_text/15-01-us.json  \n",
            "  inflating: Clean_text/20-11-us2.json  \n",
            "  inflating: Clean_text/22-04-us4.json  \n",
            "  inflating: Clean_text/19-12-us5.json  \n",
            "  inflating: Clean_text/22-05-us4.json  \n",
            "  inflating: Clean_text/21-02-us8.json  \n",
            "  inflating: Clean_text/21-03-us8.json  \n",
            "  inflating: Clean_text/21-01-us1.json  \n",
            "  inflating: Clean_text/22-02-us3.json  \n",
            "  inflating: Clean_text/22-03-us3.json  \n",
            "  inflating: Clean_text/11-06-us.json  \n",
            "  inflating: Clean_text/14-07-us.json  \n",
            "  inflating: Clean_text/21-12-us2.json  \n",
            "  inflating: Clean_text/23-06-us4.json  \n",
            "  inflating: Clean_text/23-07-us4.json  \n",
            "  inflating: Clean_text/21-09-us4.json  \n",
            "  inflating: Clean_text/21-08-us4.json  \n",
            "  inflating: Clean_text/19-06-us1.json  \n",
            "  inflating: Clean_text/19-07-us1.json  \n",
            "  inflating: Clean_text/15-08-us.json  \n",
            "  inflating: Clean_text/20-01-us4.json  \n",
            "  inflating: Clean_text/20-09-us1.json  \n",
            "  inflating: Clean_text/13-05-us.json  \n",
            "  inflating: Clean_text/21-05-us3.json  \n",
            "  inflating: Clean_text/10-09-us.json  \n",
            "  inflating: Clean_text/21-04-us3.json  \n",
            "  inflating: Clean_text/22-07-us1.json  \n",
            "  inflating: Clean_text/22-06-us1.json  \n",
            "  inflating: Clean_text/20-12-us7.json  \n",
            "  inflating: Clean_text/21-03-us4.json  \n",
            "  inflating: Clean_text/21-02-us4.json  \n",
            "  inflating: Clean_text/21-06-02-US5.json  \n",
            "  inflating: Clean_text/23-05-us1.json  \n",
            "  inflating: Clean_text/23-04-us1.json  \n",
            "  inflating: Clean_text/22-08-us3.json  \n",
            "  inflating: Clean_text/22-09-us3.json  \n",
            "  inflating: Clean_text/text_17-05-US.json  \n",
            "  inflating: Clean_text/22-12-us5.json  \n",
            "  inflating: Clean_text/12-03-us.json  \n",
            "  inflating: Clean_text/21-08-us3.json  \n",
            "  inflating: Clean_text/21-09-us3.json  \n",
            "  inflating: Clean_text/20-05-us1.json  \n",
            "  inflating: Clean_text/20-04-us1.json  \n",
            "  inflating: Clean_text/23-07-us3.json  \n",
            "  inflating: Clean_text/18-11-us2.json  \n",
            "  inflating: Clean_text/23-06-us3.json  \n",
            "   creating: Clean_text/.ipynb_checkpoints/\n",
            "  inflating: Clean_text/15-03-us.json  \n",
            "  inflating: Clean_text/21-12-us5.json  \n",
            "  inflating: Clean_text/10-12-us.json  \n",
            "  inflating: Clean_text/10-02-us.json  \n",
            "  inflating: Clean_text/22-03-us4.json  \n",
            "  inflating: Clean_text/22-02-us4.json  \n",
            "  inflating: Clean_text/21-01-us6.json  \n",
            "  inflating: Clean_text/22-05-us3.json  \n",
            "  inflating: Clean_text/19-12-us2.json  \n",
            "  inflating: Clean_text/22-04-us3.json  \n",
            "  inflating: Clean_text/20-11-us5.json  \n",
            "  inflating: Clean_text/20-10-us5.json  \n",
            "  inflating: Clean_text/23-08-us1.json  \n",
            "  inflating: Clean_text/14-05-us.json  \n",
            "  inflating: Clean_text/20_07-us7.json  \n",
            "  inflating: Clean_text/20_06-us7.json  \n",
            "  inflating: Clean_text/19-08-us4.json  \n",
            "  inflating: Clean_text/21-05-us8.json  \n",
            "  inflating: Clean_text/19-09-us4.json  \n",
            "  inflating: Clean_text/21-04-us8.json  \n",
            "  inflating: Clean_text/21-07-us1.json  \n",
            "  inflating: Clean_text/20-03-us6.json  \n",
            "  inflating: Clean_text/19-01-us1.json  \n",
            "  inflating: Clean_text/11-04-us.json  \n",
            "  inflating: Clean_text/23-01-us4.json  \n",
            "  inflating: Clean_text/12-08-us.json  \n",
            "  inflating: Clean_text/18-09-us1.json  \n",
            "  inflating: Clean_text/22-12-us2.json  \n",
            "  inflating: Clean_text/13-07-us.json  \n",
            "  inflating: Clean_text/text_16-11-US.json  \n",
            "  inflating: Clean_text/22-09-us4.json  \n",
            "  inflating: Clean_text/22-08-us4.json  \n",
            "  inflating: Clean_text/22-01-us1.json  \n",
            "  inflating: Clean_text/16-06-us.json  \n",
            "  inflating: Clean_text/21-06-02-US2.json  \n",
            "  inflating: Clean_text/21-02-us3.json  \n",
            "  inflating: Clean_text/21-03-us3.json  \n",
            "  inflating: Clean_text/20-12-us0.json  \n",
            "  inflating: Clean_text/19-11-us7.json  \n",
            "  inflating: Clean_text/21-04-us4.json  \n",
            "  inflating: Clean_text/21-05-us4.json  \n",
            "  inflating: Clean_text/12-01-us.json  \n",
            "  inflating: Clean_text/12-11-us.json  \n",
            "  inflating: Clean_text/20-01-us3.json  \n",
            "  inflating: Clean_text/23-03-us1.json  \n",
            "  inflating: Clean_text/20-01-us2.json  \n",
            "  inflating: Clean_text/13-06-us.json  \n",
            "  inflating: Clean_text/16-07-us.json  \n",
            "  inflating: Clean_text/21-04-us5.json  \n",
            "  inflating: Clean_text/21-05-us5.json  \n",
            "  inflating: Clean_text/19-11-us6.json  \n",
            "  inflating: Clean_text/20-12-us1.json  \n",
            "  inflating: Clean_text/21-02-us2.json  \n",
            "  inflating: Clean_text/21-03-us2.json  \n",
            "  inflating: Clean_text/12-10-us.json  \n",
            "  inflating: Clean_text/21-06-02-US3.json  \n",
            "  inflating: Clean_text/text_17-06-US.json  \n",
            "  inflating: Clean_text/21-10-us1.json  \n",
            "  inflating: Clean_text/21-11-us1.json  \n",
            "  inflating: Clean_text/22-09-us5.json  \n",
            "  inflating: Clean_text/22-08-us5.json  \n",
            "  inflating: Clean_text/22-12-us3.json  \n",
            "  inflating: Clean_text/19-04-us2.json  \n",
            "  inflating: Clean_text/19-05-us2.json  \n",
            "  inflating: Clean_text/23-01-us5.json  \n",
            "  inflating: Clean_text/15-12-us.json  \n",
            "  inflating: Clean_text/15-02-us.json  \n",
            "  inflating: Clean_text/20-03-us7.json  \n",
            "  inflating: Clean_text/21-05-us9.json  \n",
            "  inflating: Clean_text/19-08-us5.json  \n",
            "  inflating: Clean_text/21-04-us9.json  \n",
            "  inflating: Clean_text/19-09-us5.json  \n",
            "  inflating: Clean_text/20_07-us6.json  \n",
            "  inflating: Clean_text/20_06-us6.json  \n",
            "  inflating: Clean_text/20-11-us4.json  \n",
            "  inflating: Clean_text/20-10-us4.json  \n",
            "  inflating: Clean_text/22-05-us2.json  \n",
            "  inflating: Clean_text/19-12-us3.json  \n",
            "  inflating: Clean_text/22-04-us2.json  \n",
            "  inflating: Clean_text/21-01-us7.json  \n",
            "  inflating: Clean_text/22-03-us5.json  \n",
            "  inflating: Clean_text/22-02-us5.json  \n",
            "  inflating: Clean_text/14-04-us.json  \n",
            "  inflating: Clean_text/11-05-us.json  \n",
            "  inflating: Clean_text/21-12-us4.json  \n",
            "  inflating: Clean_text/23-07-us2.json  \n",
            "  inflating: Clean_text/23-06-us2.json  \n",
            "  inflating: Clean_text/12-09-us.json  \n",
            "  inflating: Clean_text/21-08-us2.json  \n",
            "  inflating: Clean_text/21-09-us2.json  \n",
            "  inflating: Clean_text/.ipynb_checkpoints/13-11-us-checkpoint.json  \n",
            "  inflating: Clean_text/.ipynb_checkpoints/22-08-us2-checkpoint.json  \n",
            "  inflating: Clean_text/.ipynb_checkpoints/20-03-us2-checkpoint.json  \n",
            "  inflating: Clean_text/.ipynb_checkpoints/22-08-us4-checkpoint.json  \n",
            "  inflating: Clean_text/.ipynb_checkpoints/22-07-us2-checkpoint.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "#sources = pd.read_csv('/content/drive/MyDrive/Michelle Molly/Corpus Data/Tagged Sources/merged_output.csv')\n",
        "#sources.head()\n"
      ],
      "metadata": {
        "id": "XFNPDyEa9Z-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uszipcode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wExp2RzUARiB",
        "outputId": "724f11ea-7fb5-444d-90bd-b632523369b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uszipcode\n",
            "  Downloading uszipcode-1.0.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from uszipcode) (24.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from uszipcode) (2.32.3)\n",
            "Collecting pathlib-mate (from uszipcode)\n",
            "  Downloading pathlib_mate-1.3.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting atomicwrites (from uszipcode)\n",
            "  Downloading atomicwrites-1.4.1.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fuzzywuzzy (from uszipcode)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting haversine>=2.5.0 (from uszipcode)\n",
            "  Downloading haversine-2.8.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from uszipcode) (2.0.32)\n",
            "Requirement already satisfied: sqlalchemy-mate>=1.4.28.3 in /usr/local/lib/python3.10/dist-packages (from uszipcode) (2.0.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.0->uszipcode) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.0->uszipcode) (3.0.3)\n",
            "Requirement already satisfied: prettytable<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy-mate>=1.4.28.3->uszipcode) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->uszipcode) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->uszipcode) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->uszipcode) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->uszipcode) (2024.7.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable<4.0.0,>=3.0.0->sqlalchemy-mate>=1.4.28.3->uszipcode) (0.2.13)\n",
            "Downloading uszipcode-1.0.1-py2.py3-none-any.whl (35 kB)\n",
            "Downloading haversine-2.8.1-py2.py3-none-any.whl (7.7 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading pathlib_mate-1.3.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: atomicwrites\n",
            "  Building wheel for atomicwrites (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atomicwrites: filename=atomicwrites-1.4.1-py2.py3-none-any.whl size=6940 sha256=86045d225574ecca12c1c25d35002bce4a60e18750f96c4ce22fb87cc357ab6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/07/0b/33b15f68736109f72ea0bb2499521d87312b932620737447a2\n",
            "Successfully built atomicwrites\n",
            "Installing collected packages: fuzzywuzzy, pathlib-mate, haversine, atomicwrites, uszipcode\n",
            "Successfully installed atomicwrites-1.4.1 fuzzywuzzy-0.18.0 haversine-2.8.1 pathlib-mate-1.3.2 uszipcode-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy-mate==2.0.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAvr1MSnOlGO",
        "outputId": "e330946c-d61b-4647-d71b-bc275868cf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sqlalchemy-mate==2.0.0.0\n",
            "  Downloading sqlalchemy_mate-2.0.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy-mate==2.0.0.0) (2.0.32)\n",
            "Requirement already satisfied: prettytable<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy-mate==2.0.0.0) (3.11.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable<4.0.0,>=3.0.0->sqlalchemy-mate==2.0.0.0) (0.2.13)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0.0,>=2.0.0->sqlalchemy-mate==2.0.0.0) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0.0,>=2.0.0->sqlalchemy-mate==2.0.0.0) (3.0.3)\n",
            "Downloading sqlalchemy_mate-2.0.0.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: sqlalchemy-mate\n",
            "Successfully installed sqlalchemy-mate-2.0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uszipcode import SearchEngine\n",
        "\n",
        "search = SearchEngine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsK7sY1pAIcn",
        "outputId": "76dec42f-2e51-451d-d3f3-1e67a900365d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download /root/.uszipcode/simple_db.sqlite from https://github.com/MacHu-GWU/uszipcode-project/releases/download/1.0.1.db/simple_db.sqlite ...\n",
            "  1.00 MB downloaded ...\n",
            "  2.00 MB downloaded ...\n",
            "  3.00 MB downloaded ...\n",
            "  4.00 MB downloaded ...\n",
            "  5.00 MB downloaded ...\n",
            "  6.00 MB downloaded ...\n",
            "  7.00 MB downloaded ...\n",
            "  8.00 MB downloaded ...\n",
            "  9.00 MB downloaded ...\n",
            "  10.00 MB downloaded ...\n",
            "  11.00 MB downloaded ...\n",
            "  Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "total = 0\n",
        "badzip = 0\n",
        "validzip = 0\n",
        "typo = 0\n",
        "for zip in tqdm(sources['zip_code'].values):\n",
        "  if pd.isna(zip):\n",
        "    continue\n",
        "  zip = int(zip)\n",
        "  total += 1\n",
        "  if search.by_zipcode(zip) is None:\n",
        "    badzip += 1\n",
        "    for i in range(10):\n",
        "      if search.by_zipcode(str(zip) + str(i)) is not None:\n",
        "        typo += 1\n",
        "        break\n",
        "  else:\n",
        "    validzip += 1\n",
        "\n",
        "print(\"Valid zip:\", validzip)\n",
        "print(\"Bad zip:\", badzip)\n",
        "print(\"Found alternative:\", typo)\n",
        "print(\"Total:\", total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRX3fNMV4bM9",
        "outputId": "828ea06a-ac6b-4d64-cd73-9b8c0585a7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4788730/4788730 [25:28<00:00, 3133.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid zip: 1977060\n",
            "Bad zip: 78490\n",
            "Found alternative: 14826\n",
            "Total: 2055550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmQwoHi5HDmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(sources['ID'].values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JMpk2zOFUqr",
        "outputId": "b6d49e51-5949-4ad7-ec19-eb91bac8513c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources.loc[sources['zip_code'] == 7520, 'zip_code'] = 75201\n",
        "sources.loc[sources['zip_code'] == 1809, 'zip_code'] = 18042\n",
        "\n"
      ],
      "metadata": {
        "id": "IRg5goKBIGz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "state_collections = {}\n",
        "directory = '/content/Clean_text'\n",
        "\n",
        "for file in tqdm(os.listdir(directory)):\n",
        "  with open(os.path.join(directory,file)) as f:\n",
        "      d = json.load(f)\n",
        "      #print(d)\n",
        "\n",
        "  for x in d:\n",
        "    id = int(x['text_id'])\n",
        "    if id in sources['ID'].values:\n",
        "      # get the value of the zip_code column in the row with the matching ID\n",
        "      zip_code = sources.loc[sources['ID'] == id, 'zip_code'].iloc[0]\n",
        "      # if zip_code is not NaN\n",
        "      if pd.isna(zip_code):\n",
        "        continue\n",
        "      zip_code = int(zip_code)\n",
        "      if search.by_zipcode(zip_code) is None:\n",
        "        for i in range(10):\n",
        "          if search.by_zipcode(str(zip_code) + str(i)) is not None:\n",
        "            zip_code = str(zip_code) + str(i)\n",
        "            break\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "      x['zip_code'] = zip_code\n",
        "      state = search.by_zipcode(zip_code).state\n",
        "      if state in state_collections:\n",
        "        state_collections[state].append(x)\n",
        "      else:\n",
        "        state_collections[state] = [x]\n",
        "\n",
        "for state in state_collections:\n",
        "  with open('/content/drive/MyDrive/Michelle Molly/Corpus Data/States/'+ state + '.json', 'w') as f:\n",
        "    json.dump(state_collections[state], f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G07OXv4vA_1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c56259-1f0d-431c-e8bb-eb49bd41d245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 101/398 [6:02:27<11:00:05, 133.35s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_collections.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpJjBJ-MA_rg",
        "outputId": "ce8e1b05-2035-455d-8296-fcd2812c1a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['NY', 'CA', 'GA', 'ME', 'TX', 'IL', 'DC', 'TN', 'OR', 'MN', 'MI', 'CO', 'IN', 'PA', 'MT', 'NE', 'FL', 'UT', 'NJ', 'CT', 'LA', 'WA', 'WI', 'MA', 'AL', 'OH', 'VA', 'MO', 'MD', 'WY', 'RI', 'IA', 'DE', 'AE', 'HI', 'NC', 'SC', 'KY', 'WV', 'NM', 'OK', 'AZ', 'AR', 'ID', 'NH', 'NV', 'KS', 'ND', 'SD', 'VT', 'MS', 'AK'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_ct = {'MO': 14345754, 'MN': 34208180, 'MI': 24463150, 'ME': 5113440, 'MD': 19819691, 'VT': 1427418, 'MA': 32309863, 'GA': 20071155, 'CT': 16918178, 'CO': 15667506, 'VA': 17856848, 'PA': 16953564, 'FL': 31124180, 'UT': 3773832, 'LA': 5748383, 'KY': 4463012, 'KS': 2769992, 'TX': 39664609, 'AZ': 13307110, 'TN': 13320177, 'AR': 4686714, 'AL': 2630784, 'AK': 3191779, 'AE': 393185, 'DE': 1055497, 'DC': 91253387, 'SD': 2743912, 'SC': 4336728, 'OR': 7043155, 'OK': 4465267, 'OH': 13026265, 'IN': 19898825, 'IL': 35740392, 'ID': 1535155, 'IA': 4692954, 'CA': 157794735, 'RI': 1293576, 'NY': 237432441, 'NV': 4743654, 'NM': 5581678, 'NJ': 12729183, 'NH': 2176231, 'WY': 665879, 'NE': 4643979, 'ND': 2154060, 'WV': 2555250, 'NC': 7451717, 'HI': 2655708, 'WI': 6604489, 'WA': 15700395, 'MT': 3271443, 'MS': 1391553}"
      ],
      "metadata": {
        "id": "2GMqoCkHHEX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_ct['MT']+state_ct['WY']+state_ct['CO']+state_ct['ID']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vo_PXUvH-3Z",
        "outputId": "c7c320c6-2fcf-4295-8a6b-eea69b1e26cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21139983"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_ct['CT']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGTYuYd_Xyfb",
        "outputId": "54217c60-226b-4085-ee55-d2b358b1bdd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16918178"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for st in state_ct:\n",
        "  if state_ct[st] > 15000000:\n",
        "    print(st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jrCH-7UHIAe",
        "outputId": "887a346c-69c7-4610-f568-96353b63a698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MN\n",
            "MI\n",
            "MD\n",
            "MA\n",
            "GA\n",
            "CT\n",
            "CO\n",
            "VA\n",
            "PA\n",
            "FL\n",
            "TX\n",
            "DC\n",
            "IN\n",
            "IL\n",
            "CA\n",
            "NY\n",
            "WA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for st in state_ct:\n",
        "  if state_ct[st] < 1000000:\n",
        "    print(st, state_ct[st])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eGYy7xIHeYR",
        "outputId": "235b0c88-a719-4e88-91d3-9adf4681337c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AE 393185\n",
            "WY 665879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(state_ct.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxvXO5uiHkqL",
        "outputId": "5015bfdf-52f2-42e9-fafb-fa900df0dd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect zips for congressional mapping"
      ],
      "metadata": {
        "id": "jMzILBH_RHi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory ="
      ],
      "metadata": {
        "id": "GByoBSrVRGRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}